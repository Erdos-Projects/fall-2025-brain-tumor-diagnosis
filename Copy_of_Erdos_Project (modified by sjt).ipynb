{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M5l7cDbqKkjS",
    "outputId": "ff9211c1-ba8f-475d-bbbc-ec7d73492d75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nibabel in /usr/local/lib/python3.12/dist-packages (5.3.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
      "Collecting monai\n",
      "  Downloading monai-1.5.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
      "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from nibabel) (25.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.12/dist-packages (from nibabel) (4.15.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Downloading monai-1.5.1-py3-none-any.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: monai\n",
      "Successfully installed monai-1.5.1\n"
     ]
    }
   ],
   "source": [
    "pip install nibabel torch torchvision monai numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CtO1bOYenISc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o1amFjIJncnp",
    "outputId": "7b3b3078-3abc-42eb-9ec7-8081ee373cf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 NIfTI files.\n",
      "First 5 files: ['G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0135_nifti/UCSF-PDGM-0135_DTI_eddy_L3.nii.gz', 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0135_nifti/UCSF-PDGM-0135_DTI_eddy_MD.nii.gz', 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0135_nifti/UCSF-PDGM-0135_ADC.nii.gz', 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0135_nifti/UCSF-PDGM-0135_DTI_eddy_FA.nii.gz', 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0135_nifti/UCSF-PDGM-0135_DTI_eddy_L1.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "data_directory = r\"G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0135_nifti\"\n",
    "paths = []\n",
    "# for current_dir, inner_dirs, files in os.walk(data_directory):\n",
    "#     for file in files:\n",
    "#         if file.endswith(\".nii\"):\n",
    "#             file_path = current_dir + \"/\" + file\n",
    "#             paths.append(file_path.replace(\"\\\\\",\"/\"))\n",
    "\n",
    "for root, dirs, files in os.walk(data_directory):\n",
    "    for f in files:\n",
    "        if f.endswith(\".nii\") or f.endswith(\".nii.gz\"):\n",
    "            paths.append(os.path.join(root, f).replace(\"\\\\\", \"/\"))\n",
    "\n",
    "print(f\"Found {len(paths)} NIfTI files.\")\n",
    "print(\"First 5 files:\", paths[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4pVozU1xniNG"
   },
   "outputs": [],
   "source": [
    "base_path = r\"G:/Shared drives/Fall2025BrainTumorDiagnosis/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y437qZpQnjeW",
    "outputId": "5d8e78ed-50bf-40fb-9580-d8faaf89ac48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Contents of Shared Drive:\n",
      "  📁 UCSF-PDGM-0135_nifti/\n",
      "  📁 UCSF-PDGM-0136_nifti/\n",
      "  📁 UCSF-PDGM-0137_nifti/\n",
      "  📁 UCSF-PDGM-0139_nifti/\n",
      "  📁 UCSF-PDGM-0140_nifti/\n",
      "  📁 UCSF-PDGM-0141_nifti/\n",
      "  📁 UCSF-PDGM-0142_nifti/\n",
      "  📁 UCSF-PDGM-0143_nifti/\n",
      "  📁 UCSF-PDGM-0144_nifti/\n",
      "  📁 UCSF-PDGM-0145_nifti/\n",
      "  📁 UCSF-PDGM-0146_nifti/\n",
      "  📁 UCSF-PDGM-0147_nifti/\n",
      "  📁 UCSF-PDGM-0148_nifti/\n",
      "  📁 UCSF-PDGM-0149_nifti/\n",
      "  📁 UCSF-PDGM-0150_nifti/\n",
      "  📁 UCSF-PDGM-0151_nifti/\n",
      "  📁 UCSF-PDGM-0152_nifti/\n",
      "  📁 UCSF-PDGM-0153_nifti/\n",
      "  📁 UCSF-PDGM-0154_nifti/\n",
      "  📁 UCSF-PDGM-0155_nifti/\n",
      "  📁 UCSF-PDGM-0156_nifti/\n",
      "  📁 UCSF-PDGM-0157_nifti/\n",
      "  📁 UCSF-PDGM-0158_nifti/\n",
      "  📁 UCSF-PDGM-0159_nifti/\n",
      "  📁 UCSF-PDGM-0160_nifti/\n",
      "  📁 UCSF-PDGM-0161_nifti/\n",
      "  📁 UCSF-PDGM-0162_nifti/\n",
      "  📁 UCSF-PDGM-0163_nifti/\n",
      "  📁 UCSF-PDGM-0164_nifti/\n",
      "  📁 UCSF-PDGM-0165_nifti/\n",
      "  📁 UCSF-PDGM-0166_nifti/\n",
      "  📁 UCSF-PDGM-0167_nifti/\n",
      "  📁 UCSF-PDGM-0168_nifti/\n",
      "  📁 UCSF-PDGM-0169_nifti/\n",
      "  📁 UCSF-PDGM-0170_nifti/\n",
      "  📁 UCSF-PDGM-0172_nifti/\n",
      "  📁 UCSF-PDGM-0173_nifti/\n",
      "  📁 UCSF-PDGM-0174_nifti/\n",
      "  📁 UCSF-PDGM-0176_nifti/\n",
      "  📁 UCSF-PDGM-0178_nifti/\n",
      "  📁 UCSF-PDGM-0179_nifti/\n",
      "  📁 UCSF-PDGM-0180_nifti/\n",
      "  📁 UCSF-PDGM-0182_nifti/\n",
      "  📁 UCSF-PDGM-0183_nifti/\n",
      "  📁 UCSF-PDGM-0184_nifti/\n",
      "  📁 UCSF-PDGM-0185_nifti/\n",
      "  📁 UCSF-PDGM-0186_nifti/\n",
      "  📁 UCSF-PDGM-0187_nifti/\n",
      "  📁 UCSF-PDGM-0188_nifti/\n",
      "  📁 UCSF-PDGM-0189_nifti/\n",
      "  📁 UCSF-PDGM-0190_nifti/\n",
      "  📁 UCSF-PDGM-0191_nifti/\n",
      "  📁 UCSF-PDGM-0193_nifti/\n",
      "  📁 UCSF-PDGM-0194_nifti/\n",
      "  📁 UCSF-PDGM-0195_nifti/\n",
      "  📁 UCSF-PDGM-0196_nifti/\n",
      "  📁 UCSF-PDGM-0197_nifti/\n",
      "  📁 UCSF-PDGM-0198_nifti/\n",
      "  📁 UCSF-PDGM-0200_nifti/\n",
      "  📁 UCSF-PDGM-0201_nifti/\n",
      "  📁 UCSF-PDGM-0202_nifti/\n",
      "  📁 UCSF-PDGM-0203_nifti/\n",
      "  📁 UCSF-PDGM-0204_nifti/\n",
      "  📁 UCSF-PDGM-0205_nifti/\n",
      "  📁 UCSF-PDGM-0206_nifti/\n",
      "  📁 UCSF-PDGM-0207_nifti/\n",
      "  📁 UCSF-PDGM-0208_nifti/\n",
      "  📁 UCSF-PDGM-0209_nifti/\n",
      "  📁 UCSF-PDGM-0210_nifti/\n",
      "  📁 UCSF-PDGM-0212_nifti/\n",
      "  📁 UCSF-PDGM-0213_nifti/\n",
      "  📁 UCSF-PDGM-0214_nifti/\n",
      "  📁 UCSF-PDGM-0215_nifti/\n",
      "  📁 UCSF-PDGM-0223_nifti/\n",
      "  📁 UCSF-PDGM-0225_nifti/\n",
      "  📁 UCSF-PDGM-0227_nifti/\n",
      "  📁 UCSF-PDGM-0228_nifti/\n",
      "  📁 UCSF-PDGM-0229_nifti/\n",
      "  📁 UCSF-PDGM-0231_nifti/\n",
      "  📁 UCSF-PDGM-0232_nifti/\n",
      "  📁 UCSF-PDGM-0233_nifti/\n",
      "  📁 UCSF-PDGM-0234_nifti/\n",
      "  📁 UCSF-PDGM-0235_nifti/\n",
      "  📁 UCSF-PDGM-0236_nifti/\n",
      "  📁 UCSF-PDGM-0237_nifti/\n",
      "  📁 UCSF-PDGM-0238_nifti/\n",
      "  📁 UCSF-PDGM-0239_nifti/\n",
      "  📁 UCSF-PDGM-0240_nifti/\n",
      "  📁 UCSF-PDGM-0241_nifti/\n",
      "  📁 UCSF-PDGM-0242_nifti/\n",
      "  📁 UCSF-PDGM-0243_nifti/\n",
      "  📁 UCSF-PDGM-0244_nifti/\n",
      "  📁 UCSF-PDGM-0245_nifti/\n",
      "  📁 UCSF-PDGM-0246_nifti/\n",
      "  📁 UCSF-PDGM-0247_nifti/\n",
      "  📁 UCSF-PDGM-0248_nifti/\n",
      "  📁 UCSF-PDGM-0249_nifti/\n",
      "  📁 UCSF-PDGM-0250_nifti/\n",
      "  📁 UCSF-PDGM-0251_nifti/\n",
      "  📁 UCSF-PDGM-0252_nifti/\n",
      "  📁 UCSF-PDGM-0253_nifti/\n",
      "  📁 UCSF-PDGM-0254_nifti/\n",
      "  📁 UCSF-PDGM-0255_nifti/\n",
      "  📁 UCSF-PDGM-0256_nifti/\n",
      "  📁 UCSF-PDGM-0257_nifti/\n",
      "  📁 UCSF-PDGM-0258_nifti/\n",
      "  📁 UCSF-PDGM-0259_nifti/\n",
      "  📁 UCSF-PDGM-0260_nifti/\n",
      "  📁 UCSF-PDGM-0261_nifti/\n",
      "  📁 UCSF-PDGM-0262_nifti/\n",
      "  📁 UCSF-PDGM-0263_nifti/\n",
      "  📁 UCSF-PDGM-0264_nifti/\n",
      "  📁 UCSF-PDGM-0265_nifti/\n",
      "  📁 UCSF-PDGM-0266_nifti/\n",
      "  📁 UCSF-PDGM-0267_nifti/\n",
      "  📁 UCSF-PDGM-0268_nifti/\n",
      "  📁 UCSF-PDGM-0269_nifti/\n",
      "  📁 UCSF-PDGM-0270_nifti/\n",
      "  📁 UCSF-PDGM-0272_nifti/\n",
      "  📁 UCSF-PDGM-0273_nifti/\n",
      "  📁 UCSF-PDGM-0274_nifti/\n",
      "  📁 UCSF-PDGM-0275_nifti/\n",
      "  📁 UCSF-PDGM-0276_nifti/\n",
      "  📁 UCSF-PDGM-0277_nifti/\n",
      "  📁 UCSF-PDGM-0279_nifti/\n",
      "  📁 UCSF-PDGM-0280_nifti/\n",
      "  📁 UCSF-PDGM-0281_nifti/\n",
      "  📁 UCSF-PDGM-0282_nifti/\n",
      "  📁 UCSF-PDGM-0283_nifti/\n",
      "  📁 UCSF-PDGM-0284_nifti/\n",
      "  📁 UCSF-PDGM-0285_nifti/\n",
      "  📁 UCSF-PDGM-0286_nifti/\n",
      "  📁 UCSF-PDGM-0287_nifti/\n",
      "  📁 UCSF-PDGM-0288_nifti/\n",
      "  📁 UCSF-PDGM-0290_nifti/\n",
      "  📁 UCSF-PDGM-0291_nifti/\n",
      "  📁 UCSF-PDGM-0295_nifti/\n",
      "  📁 UCSF-PDGM-0296_nifti/\n",
      "  📁 UCSF-PDGM-0297_nifti/\n",
      "  📁 UCSF-PDGM-0298_nifti/\n",
      "  📁 UCSF-PDGM-0300_nifti/\n",
      "  📁 UCSF-PDGM-0302_nifti/\n",
      "  📁 UCSF-PDGM-0303_nifti/\n",
      "  📁 UCSF-PDGM-0304_nifti/\n",
      "  📁 UCSF-PDGM-0305_nifti/\n",
      "  📁 UCSF-PDGM-0306_nifti/\n",
      "  📁 UCSF-PDGM-0307_nifti/\n",
      "  📁 UCSF-PDGM-0308_nifti/\n",
      "  📁 UCSF-PDGM-0309_nifti/\n",
      "  📁 UCSF-PDGM-0310_nifti/\n",
      "  📁 UCSF-PDGM-0311_nifti/\n",
      "  📁 UCSF-PDGM-0312_nifti/\n",
      "  📁 UCSF-PDGM-0313_nifti/\n",
      "  📁 UCSF-PDGM-0314_nifti/\n",
      "  📁 UCSF-PDGM-0316_nifti/\n",
      "  📁 UCSF-PDGM-0317_nifti/\n",
      "  📁 UCSF-PDGM-0318_nifti/\n",
      "  📁 UCSF-PDGM-0319_nifti/\n",
      "  📁 UCSF-PDGM-0320_nifti/\n",
      "  📁 UCSF-PDGM-0321_nifti/\n",
      "  📁 UCSF-PDGM-0323_nifti/\n",
      "  📁 UCSF-PDGM-0324_nifti/\n",
      "  📁 UCSF-PDGM-0325_nifti/\n",
      "  📁 UCSF-PDGM-0326_nifti/\n",
      "  📁 UCSF-PDGM-0327_nifti/\n",
      "  📁 UCSF-PDGM-0328_nifti/\n",
      "  📁 UCSF-PDGM-0329_nifti/\n",
      "  📁 UCSF-PDGM-0330_nifti/\n",
      "  📁 UCSF-PDGM-0331_nifti/\n",
      "  📁 UCSF-PDGM-0332_nifti/\n",
      "  📁 UCSF-PDGM-0333_nifti/\n",
      "  📁 UCSF-PDGM-0334_nifti/\n",
      "  📁 UCSF-PDGM-0335_nifti/\n",
      "  📁 UCSF-PDGM-0336_nifti/\n",
      "  📁 UCSF-PDGM-0337_nifti/\n",
      "  📁 UCSF-PDGM-0338_nifti/\n",
      "  📁 UCSF-PDGM-0339_nifti/\n",
      "  📁 UCSF-PDGM-0340_nifti/\n",
      "  📁 UCSF-PDGM-0341_nifti/\n",
      "  📁 UCSF-PDGM-0342_nifti/\n",
      "  📁 UCSF-PDGM-0343_nifti/\n",
      "  📁 UCSF-PDGM-0344_nifti/\n",
      "  📁 UCSF-PDGM-0345_nifti/\n",
      "  📁 UCSF-PDGM-0346_nifti/\n",
      "  📁 UCSF-PDGM-0347_nifti/\n",
      "  📁 UCSF-PDGM-0348_nifti/\n",
      "  📁 UCSF-PDGM-0349_nifti/\n",
      "  📁 UCSF-PDGM-0350_nifti/\n",
      "  📁 UCSF-PDGM-0351_nifti/\n",
      "  📁 UCSF-PDGM-0352_nifti/\n",
      "  📁 UCSF-PDGM-0353_nifti/\n",
      "  📁 UCSF-PDGM-0354_nifti/\n",
      "  📁 UCSF-PDGM-0355_nifti/\n",
      "  📁 UCSF-PDGM-0356_nifti/\n",
      "  📁 UCSF-PDGM-0357_nifti/\n",
      "  📁 UCSF-PDGM-0358_nifti/\n",
      "  📁 UCSF-PDGM-0359_nifti/\n",
      "  📁 UCSF-PDGM-0360_nifti/\n",
      "  📁 UCSF-PDGM-0361_nifti/\n",
      "  📁 UCSF-PDGM-0362_nifti/\n",
      "  📁 UCSF-PDGM-0363_nifti/\n",
      "  📁 UCSF-PDGM-0364_nifti/\n",
      "  📁 UCSF-PDGM-0365_nifti/\n",
      "  📁 UCSF-PDGM-0366_nifti/\n",
      "  📁 UCSF-PDGM-0367_nifti/\n",
      "  📁 UCSF-PDGM-0368_nifti/\n",
      "  📁 UCSF-PDGM-0369_nifti/\n",
      "  📁 UCSF-PDGM-0370_nifti/\n",
      "  📁 UCSF-PDGM-0371_nifti/\n",
      "  📁 UCSF-PDGM-0372_nifti/\n",
      "  📁 UCSF-PDGM-0373_nifti/\n",
      "  📁 UCSF-PDGM-0374_nifti/\n",
      "  📁 UCSF-PDGM-0375_nifti/\n",
      "  📁 UCSF-PDGM-0376_nifti/\n",
      "  📁 UCSF-PDGM-0377_nifti/\n",
      "  📁 UCSF-PDGM-0378_nifti/\n",
      "  📁 UCSF-PDGM-0379_nifti/\n",
      "  📁 UCSF-PDGM-0380_nifti/\n",
      "  📁 UCSF-PDGM-0381_nifti/\n",
      "  📁 UCSF-PDGM-0382_nifti/\n",
      "  📁 UCSF-PDGM-0383_nifti/\n",
      "  📁 UCSF-PDGM-0384_nifti/\n",
      "  📁 UCSF-PDGM-0385_nifti/\n",
      "  📁 UCSF-PDGM-0386_nifti/\n",
      "  📁 UCSF-PDGM-0387_nifti/\n",
      "  📁 UCSF-PDGM-0388_nifti/\n",
      "  📁 UCSF-PDGM-0389_nifti/\n",
      "  📁 UCSF-PDGM-0390_nifti/\n",
      "  📄 desktop.ini\n",
      "Total patient folders: 228\n",
      "\n",
      "First 5 patients:\n",
      "  📁 UCSF-PDGM-0135_nifti\n",
      "  📁 UCSF-PDGM-0136_nifti\n",
      "  📁 UCSF-PDGM-0137_nifti\n",
      "  📁 UCSF-PDGM-0139_nifti\n",
      "  📁 UCSF-PDGM-0140_nifti\n",
      "\n",
      "📂 Scans in UCSF-PDGM-0135_nifti:\n",
      "Total scans: 23\n",
      "\n",
      "1. UCSF-PDGM-0135_ADC.nii.gz\n",
      "2. UCSF-PDGM-0135_ASL.nii.gz\n",
      "3. UCSF-PDGM-0135_DTI_eddy.eddy_rotated_bvecs\n",
      "4. UCSF-PDGM-0135_DTI_eddy_FA.nii.gz\n",
      "5. UCSF-PDGM-0135_DTI_eddy_L1.nii.gz\n",
      "6. UCSF-PDGM-0135_DTI_eddy_L2.nii.gz\n",
      "7. UCSF-PDGM-0135_DTI_eddy_L3.nii.gz\n",
      "8. UCSF-PDGM-0135_DTI_eddy_MD.nii.gz\n",
      "9. UCSF-PDGM-0135_DWI.nii.gz\n",
      "10. UCSF-PDGM-0135_DWI_bias.nii.gz\n",
      "11. UCSF-PDGM-0135_FLAIR.nii.gz\n",
      "12. UCSF-PDGM-0135_FLAIR_bias.nii.gz\n",
      "13. UCSF-PDGM-0135_SWI.nii.gz\n",
      "14. UCSF-PDGM-0135_SWI_bias.nii.gz\n",
      "15. UCSF-PDGM-0135_T1.nii.gz\n",
      "16. UCSF-PDGM-0135_T1_bias.nii.gz\n",
      "17. UCSF-PDGM-0135_T1c.nii.gz\n",
      "18. UCSF-PDGM-0135_T1c_bias.nii.gz\n",
      "19. UCSF-PDGM-0135_T2.nii.gz\n",
      "20. UCSF-PDGM-0135_T2_bias.nii.gz\n",
      "21. UCSF-PDGM-0135_brain_parenchyma_segmentation.nii.gz\n",
      "22. UCSF-PDGM-0135_brain_segmentation.nii.gz\n",
      "23. UCSF-PDGM-0135_tumor_segmentation.nii.gz\n",
      "\n",
      "📄 Looking for label files in base directory:\n"
     ]
    }
   ],
   "source": [
    "print(\"📂 Contents of Shared Drive:\")\n",
    "for item in sorted(os.listdir(base_path)):\n",
    "    full_path = os.path.join(base_path, item)\n",
    "    if os.path.isfile(full_path):\n",
    "        print(f\"  📄 {item}\")\n",
    "    else:\n",
    "        print(f\"  📁 {item}/\")\n",
    "\n",
    "# Get all patient folders\n",
    "patient_folders = sorted([f for f in os.listdir(base_path)\n",
    "                         if os.path.isdir(os.path.join(base_path, f))])\n",
    "\n",
    "print(f\"Total patient folders: {len(patient_folders)}\")\n",
    "print(f\"\\nFirst 5 patients:\")\n",
    "for folder in patient_folders[:5]:\n",
    "    print(f\"  📁 {folder}\")\n",
    "\n",
    "# Check scans in the first patient\n",
    "first_patient = patient_folders[0]\n",
    "patient_path = os.path.join(base_path, first_patient)\n",
    "scans = sorted(os.listdir(patient_path))\n",
    "\n",
    "print(f\"\\n📂 Scans in {first_patient}:\")\n",
    "print(f\"Total scans: {len(scans)}\\n\")\n",
    "for i, scan in enumerate(scans, 1):\n",
    "    print(f\"{i}. {scan}\")\n",
    "\n",
    "# Check for label files in base directory\n",
    "print(\"\\n📄 Looking for label files in base directory:\")\n",
    "for item in os.listdir(base_path):\n",
    "    if item.endswith(('.csv', '.txt', '.xlsx', '.json')):\n",
    "        print(f\"  Found: {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q8mZVNRSnu5q",
    "outputId": "5f9dd4a1-a890-4de3-c5b9-4322bec6fb76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking all 228 patients...\n",
      "\n",
      "\n",
      "==================================================\n",
      "SUMMARY:\n",
      "  Total patients: 228\n",
      "  Has tumor: 228\n",
      "  No tumor: 0\n",
      "  Errors: 0\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "patient_folders = sorted([f for f in os.listdir(base_path)\n",
    "                         if os.path.isdir(os.path.join(base_path, f))])\n",
    "\n",
    "tumor_count = 0\n",
    "no_tumor_count = 0\n",
    "error_count = 0\n",
    "\n",
    "print(\"Checking all 228 patients...\\n\")\n",
    "\n",
    "for patient in patient_folders:\n",
    "    tumor_seg_path = os.path.join(base_path, patient,\n",
    "                                   f\"{patient.replace('_nifti', '')}_tumor_segmentation.nii.gz\")\n",
    "\n",
    "    try:\n",
    "        img = nib.load(tumor_seg_path).get_fdata()\n",
    "        if np.any(img > 0):\n",
    "            tumor_count += 1\n",
    "        else:\n",
    "            no_tumor_count += 1\n",
    "            print(f\"NO TUMOR: {patient}\")  # Print patients without tumor\n",
    "    except:\n",
    "        error_count += 1\n",
    "        print(f\"ERROR loading: {patient}\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"SUMMARY:\")\n",
    "print(f\"  Total patients: {len(patient_folders)}\")\n",
    "print(f\"  Has tumor: {tumor_count}\")\n",
    "print(f\"  No tumor: {no_tumor_count}\")\n",
    "print(f\"  Errors: {error_count}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zyDirrjCn1L8",
    "outputId": "78d8d50b-8525-4336-8bfd-b0d5364f4f73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n",
      "Shape: 501 rows × 16 columns\n",
      "\n",
      "Column names:\n",
      "  1. ID\n",
      "  2. Sex\n",
      "  3. Age at MRI\n",
      "  4. WHO CNS Grade\n",
      "  5. Final pathologic diagnosis (WHO 2021)\n",
      "  6. MGMT status\n",
      "  7. MGMT index\n",
      "  8. 1p/19q\n",
      "  9. IDH\n",
      "  10. 1-dead 0-alive\n",
      "  11. OS\n",
      "  12. EOR\n",
      "  13. Biopsy prior to imaging\n",
      "  14. BraTS21 ID\n",
      "  15. BraTS21 Segmentation Cohort\n",
      "  16. BraTS21 MGMT Cohort\n",
      "\n",
      "First 5 rows:\n",
      "              ID Sex  Age at MRI  WHO CNS Grade  \\\n",
      "0  UCSF-PDGM-004   M          66              4   \n",
      "1  UCSF-PDGM-005   F          80              4   \n",
      "2  UCSF-PDGM-007   M          70              4   \n",
      "3  UCSF-PDGM-008   M          70              4   \n",
      "4  UCSF-PDGM-009   F          68              4   \n",
      "\n",
      "  Final pathologic diagnosis (WHO 2021)    MGMT status MGMT index   1p/19q  \\\n",
      "0            Glioblastoma, IDH-wildtype       negative          0  unknown   \n",
      "1            Glioblastoma, IDH-wildtype  indeterminate    unknown  unknown   \n",
      "2            Glioblastoma, IDH-wildtype  indeterminate    unknown  unknown   \n",
      "3            Glioblastoma, IDH-wildtype       negative          0  unknown   \n",
      "4            Glioblastoma, IDH-wildtype       negative          0  unknown   \n",
      "\n",
      "        IDH  1-dead 0-alive      OS     EOR Biopsy prior to imaging  \\\n",
      "0  wildtype               1  1303.0     STR                      No   \n",
      "1  wildtype               1   274.0  biopsy                      No   \n",
      "2  wildtype               1   417.0     STR                      No   \n",
      "3  wildtype               1   185.0     STR                      No   \n",
      "4  wildtype               1   389.0     STR                      No   \n",
      "\n",
      "        BraTS21 ID BraTS21 Segmentation Cohort BraTS21 MGMT Cohort  \n",
      "0  BraTS2021_00097                    Training            Training  \n",
      "1              NaN                         NaN                 NaN  \n",
      "2  BraTS2021_00103                    Training                 NaN  \n",
      "3              NaN                         NaN                 NaN  \n",
      "4  BraTS2021_00049                    Training            Training  \n",
      "\n",
      "Checking for patient ID column...\n",
      "Potential ID columns: ['ID', 'IDH', 'BraTS21 ID']\n",
      "\n",
      "Sample values from 'ID':\n",
      "0    UCSF-PDGM-004\n",
      "1    UCSF-PDGM-005\n",
      "2    UCSF-PDGM-007\n",
      "3    UCSF-PDGM-008\n",
      "4    UCSF-PDGM-009\n",
      "5    UCSF-PDGM-010\n",
      "6    UCSF-PDGM-011\n",
      "7    UCSF-PDGM-012\n",
      "8    UCSF-PDGM-013\n",
      "9    UCSF-PDGM-014\n",
      "Name: ID, dtype: object\n"
     ]
    }
   ],
   "source": [
    "csv_path=\"fall-2025-brain-tumor-diagnosis/Clinical-data/UCSF-PDGM-metadata_v5.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Display basic info\n",
    "print(f\"CSV loaded successfully!\")\n",
    "print(f\"Shape: {df.shape[0]} rows × {df.shape[1]} columns\\n\")\n",
    "\n",
    "# Show column names\n",
    "print(\"Column names:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "\n",
    "# Show first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check if there's a patient ID column that matches our folder names\n",
    "print(\"\\nChecking for patient ID column...\")\n",
    "potential_id_cols = [col for col in df.columns if 'id' in col.lower() or 'patient' in col.lower() or 'case' in col.lower()]\n",
    "if potential_id_cols:\n",
    "    print(f\"Potential ID columns: {potential_id_cols}\")\n",
    "    print(f\"\\nSample values from '{potential_id_cols[0]}':\")\n",
    "    print(df[potential_id_cols[0]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vBb1vpZaoFFG",
    "outputId": "c252af10-84fb-415b-d617-6ed4fcdeec8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patients in CSV: 501\n",
      "Total folders: 228\n",
      "Matched patients (have both data and labels): 228\n",
      "\n",
      "==================================================\n",
      "WHO Grade distribution:\n",
      "WHO CNS Grade\n",
      "2     39\n",
      "3     24\n",
      "4    165\n",
      "Name: count, dtype: int64\n",
      "==================================================\n",
      "\n",
      "First 5 matched patients:\n",
      "                ID           folder_name  WHO CNS Grade\n",
      "117  UCSF-PDGM-135  UCSF-PDGM-0135_nifti              4\n",
      "118  UCSF-PDGM-136  UCSF-PDGM-0136_nifti              4\n",
      "119  UCSF-PDGM-137  UCSF-PDGM-0137_nifti              4\n",
      "121  UCSF-PDGM-139  UCSF-PDGM-0139_nifti              4\n",
      "122  UCSF-PDGM-140  UCSF-PDGM-0140_nifti              4\n",
      "\n",
      "Labels dictionary created!\n",
      "Example entries:\n",
      "  UCSF-PDGM-0135_nifti: Grade 4\n",
      "  UCSF-PDGM-0136_nifti: Grade 4\n",
      "  UCSF-PDGM-0137_nifti: Grade 4\n",
      "  UCSF-PDGM-0139_nifti: Grade 4\n",
      "  UCSF-PDGM-0140_nifti: Grade 4\n"
     ]
    }
   ],
   "source": [
    "# Get patient folders\n",
    "patient_folders = sorted([f for f in os.listdir(base_path)\n",
    "                         if os.path.isdir(os.path.join(base_path, f))])\n",
    "\n",
    "# Extract patient number and pad to 4 digits\n",
    "df['patient_num'] = df['ID'].str.extract(r'UCSF-PDGM-(\\d+)')[0]\n",
    "df['folder_name'] = 'UCSF-PDGM-' + df['patient_num'].str.zfill(4) + '_nifti'\n",
    "\n",
    "# Filter to only patients we have imaging data for\n",
    "df_with_imaging = df[df['folder_name'].isin(patient_folders)]\n",
    "\n",
    "print(f\"Total patients in CSV: {len(df)}\")\n",
    "print(f\"Total folders: {len(patient_folders)}\")\n",
    "print(f\"Matched patients (have both data and labels): {len(df_with_imaging)}\")\n",
    "\n",
    "# Check WHO Grade distribution\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"WHO Grade distribution:\")\n",
    "print(df_with_imaging['WHO CNS Grade'].value_counts().sort_index())\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Show first few matches\n",
    "print(f\"\\nFirst 5 matched patients:\")\n",
    "print(df_with_imaging[['ID', 'folder_name', 'WHO CNS Grade']].head())\n",
    "\n",
    "# Create labels dictionary\n",
    "labels_dict = dict(zip(df_with_imaging['folder_name'],\n",
    "                       df_with_imaging['WHO CNS Grade']))\n",
    "\n",
    "print(f\"\\nLabels dictionary created!\")\n",
    "print(f\"Example entries:\")\n",
    "for i, (folder, grade) in enumerate(list(labels_dict.items())[:5]):\n",
    "    print(f\"  {folder}: Grade {grade}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "P1Tt-qGdm7gD",
    "outputId": "6497a0a8-dc41-447a-c1ce-3fb1dc796e1f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows 10\\AppData\\Local\\Temp\\ipykernel_2964\\3704298045.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_matched['class_label'] = df_matched['WHO CNS Grade'].map(grade_to_class)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 228 patients with labels\n",
      "Class distribution: WHO CNS Grade\n",
      "2     39\n",
      "3     24\n",
      "4    165\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Train: 182, Val: 46\n",
      "Using 7 modalities: ['ADC', 'FLAIR', 'T1']... (showing first 3)\n",
      "Using 7 modalities: ['ADC', 'FLAIR', 'T1']... (showing first 3)\n",
      "\n",
      "Using device: cpu\n",
      "\n",
      "Starting training...\n",
      "Warning: Could not load ADC for UCSF-PDGM-0368_nifti: No such file or no access: 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0368_nifti/UCSF-PDGM-0368_ADC.nii.gz'\n",
      "Warning: Could not load FLAIR for UCSF-PDGM-0368_nifti: No such file or no access: 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0368_nifti/UCSF-PDGM-0368_FLAIR.nii.gz'\n",
      "Warning: Could not load T1 for UCSF-PDGM-0368_nifti: No such file or no access: 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0368_nifti/UCSF-PDGM-0368_T1.nii.gz'\n",
      "Warning: Could not load T1c for UCSF-PDGM-0368_nifti: No such file or no access: 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0368_nifti/UCSF-PDGM-0368_T1c.nii.gz'\n",
      "Warning: Could not load T2 for UCSF-PDGM-0368_nifti: No such file or no access: 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0368_nifti/UCSF-PDGM-0368_T2.nii.gz'\n",
      "Warning: Could not load brain_segmentation for UCSF-PDGM-0368_nifti: No such file or no access: 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0368_nifti/UCSF-PDGM-0368_brain_segmentation.nii.gz'\n",
      "Warning: Could not load tumor_segmentation for UCSF-PDGM-0368_nifti: No such file or no access: 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0368_nifti/UCSF-PDGM-0368_tumor_segmentation.nii.gz'\n",
      "Warning: Could not load ADC for UCSF-PDGM-0386_nifti: No such file or no access: 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0386_nifti/UCSF-PDGM-0386_ADC.nii.gz'\n",
      "Warning: Could not load FLAIR for UCSF-PDGM-0386_nifti: No such file or no access: 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0386_nifti/UCSF-PDGM-0386_FLAIR.nii.gz'\n",
      "Warning: Could not load T1 for UCSF-PDGM-0386_nifti: No such file or no access: 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0386_nifti/UCSF-PDGM-0386_T1.nii.gz'\n",
      "Warning: Could not load T1c for UCSF-PDGM-0386_nifti: No such file or no access: 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0386_nifti/UCSF-PDGM-0386_T1c.nii.gz'\n",
      "Warning: Could not load T2 for UCSF-PDGM-0386_nifti: No such file or no access: 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0386_nifti/UCSF-PDGM-0386_T2.nii.gz'\n",
      "Warning: Could not load brain_segmentation for UCSF-PDGM-0386_nifti: No such file or no access: 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0386_nifti/UCSF-PDGM-0386_brain_segmentation.nii.gz'\n",
      "Warning: Could not load tumor_segmentation for UCSF-PDGM-0386_nifti: No such file or no access: 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0386_nifti/UCSF-PDGM-0386_tumor_segmentation.nii.gz'\n",
      "Warning: Could not load ADC for UCSF-PDGM-0319_nifti: No such file or no access: 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0319_nifti/UCSF-PDGM-0319_ADC.nii.gz'\n",
      "Warning: Could not load FLAIR for UCSF-PDGM-0319_nifti: No such file or no access: 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0319_nifti/UCSF-PDGM-0319_FLAIR.nii.gz'\n",
      "Warning: Could not load T1 for UCSF-PDGM-0319_nifti: No such file or no access: 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0319_nifti/UCSF-PDGM-0319_T1.nii.gz'\n",
      "Warning: Could not load T1c for UCSF-PDGM-0319_nifti: No such file or no access: 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0319_nifti/UCSF-PDGM-0319_T1c.nii.gz'\n",
      "Warning: Could not load T2 for UCSF-PDGM-0319_nifti: No such file or no access: 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0319_nifti/UCSF-PDGM-0319_T2.nii.gz'\n",
      "Warning: Could not load brain_segmentation for UCSF-PDGM-0319_nifti: No such file or no access: 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0319_nifti/UCSF-PDGM-0319_brain_segmentation.nii.gz'\n",
      "Warning: Could not load tumor_segmentation for UCSF-PDGM-0319_nifti: No such file or no access: 'G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0319_nifti/UCSF-PDGM-0319_tumor_segmentation.nii.gz'\n",
      "Warning: Could not load T1c for UCSF-PDGM-0160_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0160_nifti/UCSF-PDGM-0160_T1c.nii.gz\n",
      "Warning: Could not load T2 for UCSF-PDGM-0160_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0160_nifti/UCSF-PDGM-0160_T2.nii.gz\n",
      "Warning: Could not load brain_segmentation for UCSF-PDGM-0160_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0160_nifti/UCSF-PDGM-0160_brain_segmentation.nii.gz\n",
      "Warning: Could not load tumor_segmentation for UCSF-PDGM-0160_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0160_nifti/UCSF-PDGM-0160_tumor_segmentation.nii.gz\n",
      "Warning: Could not load ADC for UCSF-PDGM-0234_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0234_nifti/UCSF-PDGM-0234_ADC.nii.gz\n",
      "Warning: Could not load FLAIR for UCSF-PDGM-0234_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0234_nifti/UCSF-PDGM-0234_FLAIR.nii.gz\n",
      "Warning: Could not load T1 for UCSF-PDGM-0234_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0234_nifti/UCSF-PDGM-0234_T1.nii.gz\n",
      "Warning: Could not load T1c for UCSF-PDGM-0234_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0234_nifti/UCSF-PDGM-0234_T1c.nii.gz\n",
      "Warning: Could not load T2 for UCSF-PDGM-0234_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0234_nifti/UCSF-PDGM-0234_T2.nii.gz\n",
      "Warning: Could not load brain_segmentation for UCSF-PDGM-0234_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0234_nifti/UCSF-PDGM-0234_brain_segmentation.nii.gz\n",
      "Warning: Could not load tumor_segmentation for UCSF-PDGM-0234_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0234_nifti/UCSF-PDGM-0234_tumor_segmentation.nii.gz\n",
      "Warning: Could not load ADC for UCSF-PDGM-0195_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0195_nifti/UCSF-PDGM-0195_ADC.nii.gz\n",
      "Warning: Could not load FLAIR for UCSF-PDGM-0195_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0195_nifti/UCSF-PDGM-0195_FLAIR.nii.gz\n",
      "Warning: Could not load T1 for UCSF-PDGM-0195_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0195_nifti/UCSF-PDGM-0195_T1.nii.gz\n",
      "Warning: Could not load T1c for UCSF-PDGM-0195_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0195_nifti/UCSF-PDGM-0195_T1c.nii.gz\n",
      "Warning: Could not load T2 for UCSF-PDGM-0195_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0195_nifti/UCSF-PDGM-0195_T2.nii.gz\n",
      "Warning: Could not load brain_segmentation for UCSF-PDGM-0195_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0195_nifti/UCSF-PDGM-0195_brain_segmentation.nii.gz\n",
      "Warning: Could not load tumor_segmentation for UCSF-PDGM-0195_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0195_nifti/UCSF-PDGM-0195_tumor_segmentation.nii.gz\n",
      "Warning: Could not load ADC for UCSF-PDGM-0209_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0209_nifti/UCSF-PDGM-0209_ADC.nii.gz\n",
      "Warning: Could not load FLAIR for UCSF-PDGM-0209_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0209_nifti/UCSF-PDGM-0209_FLAIR.nii.gz\n",
      "Warning: Could not load T1c for UCSF-PDGM-0209_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0209_nifti/UCSF-PDGM-0209_T1c.nii.gz\n",
      "Warning: Could not load T2 for UCSF-PDGM-0209_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0209_nifti/UCSF-PDGM-0209_T2.nii.gz\n",
      "Warning: Could not load brain_segmentation for UCSF-PDGM-0209_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0209_nifti/UCSF-PDGM-0209_brain_segmentation.nii.gz\n",
      "Warning: Could not load tumor_segmentation for UCSF-PDGM-0209_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0209_nifti/UCSF-PDGM-0209_tumor_segmentation.nii.gz\n",
      "Warning: Could not load ADC for UCSF-PDGM-0170_nifti: Could not read file: G:/Shared drives/Fall2025BrainTumorDiagnosis/UCSF-PDGM-0170_nifti/UCSF-PDGM-0170_ADC.nii.gz\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 294\u001b[39m\n\u001b[32m    292\u001b[39m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mStarting training...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m train_losses, val_losses, train_accs, val_accs = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[38;5;66;03m# Plot results\u001b[39;00m\n\u001b[32m    300\u001b[39m fig, (ax1, ax2) = plt.subplots(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, figsize=(\u001b[32m12\u001b[39m, \u001b[32m4\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 203\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\u001b[39m\n\u001b[32m    200\u001b[39m correct = \u001b[32m0\u001b[39m\n\u001b[32m    201\u001b[39m total = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda3\\envs\\erdos_ds_environment\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda3\\envs\\erdos_ds_environment\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda3\\envs\\erdos_ds_environment\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mMRIDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     86\u001b[39m file_path = patient_path / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpatient_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodality\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.nii.gz\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# ✅ Safe path\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Load 3D volume\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     img_3d = \u001b[43mnib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.get_fdata().astype(np.float32)  \u001b[38;5;66;03m# ✅ Convert to string\u001b[39;00m\n\u001b[32m     92\u001b[39m     \u001b[38;5;66;03m# Extract 2D slice\u001b[39;00m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m img_3d.shape[\u001b[32m2\u001b[39m] > \u001b[38;5;28mself\u001b[39m.slice_idx:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda3\\envs\\erdos_ds_environment\\Lib\\site-packages\\nibabel\\loadsave.py:114\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filename, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m         img = image_klass.from_filename(filename, **kwargs)\n\u001b[32m    112\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m img\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m matches, msg = \u001b[43m_signature_matches_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m matches:\n\u001b[32m    116\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ImageFileError(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda3\\envs\\erdos_ds_environment\\Lib\\site-packages\\nibabel\\loadsave.py:72\u001b[39m, in \u001b[36m_signature_matches_extension\u001b[39m\u001b[34m(filename)\u001b[39m\n\u001b[32m     70\u001b[39m expected_signature = signatures[ext][\u001b[33m'\u001b[39m\u001b[33msignature\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[32m     73\u001b[39m         sniff = fh.read(\u001b[38;5;28mlen\u001b[39m(expected_signature))\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# 1. LOAD AND PREPARE LABELS\n",
    "# =============================================\n",
    "\n",
    "def load_labels(csv_path, base_path):\n",
    "    \"\"\"\n",
    "    Load labels from CSV and match to folder names\n",
    "\n",
    "    Args:\n",
    "        csv_path: Path to metadata CSV file\n",
    "        base_path: Path to folder containing patient folders\n",
    "\n",
    "    Returns:\n",
    "        labels_dict: Dictionary mapping folder_name -> grade (0, 1, 2)\n",
    "        patient_folders: List of patient folder names\n",
    "    \"\"\"\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Get all patient folders\n",
    "    patient_folders = sorted([f for f in os.listdir(base_path)\n",
    "                             if os.path.isdir(os.path.join(base_path, f))])\n",
    "\n",
    "    # Match CSV IDs to folder names (pad numbers to 4 digits)\n",
    "    df['patient_num'] = df['ID'].str.extract(r'UCSF-PDGM-(\\d+)')[0]\n",
    "    df['folder_name'] = 'UCSF-PDGM-' + df['patient_num'].str.zfill(4) + '_nifti'\n",
    "\n",
    "    # Filter to patients with imaging data\n",
    "    df_matched = df[df['folder_name'].isin(patient_folders)]\n",
    "\n",
    "    # Convert WHO grades to class indices: Grade 2->0, Grade 3->1, Grade 4->2\n",
    "    grade_to_class = {2: 0, 3: 1, 4: 2}\n",
    "    df_matched['class_label'] = df_matched['WHO CNS Grade'].map(grade_to_class)\n",
    "\n",
    "    # Create labels dictionary\n",
    "    labels_dict = dict(zip(df_matched['folder_name'], df_matched['class_label']))\n",
    "\n",
    "    print(f\"Loaded {len(labels_dict)} patients with labels\")\n",
    "    print(f\"Class distribution: {df_matched['WHO CNS Grade'].value_counts().sort_index()}\")\n",
    "\n",
    "    return labels_dict, patient_folders\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# 2. DATASET CLASS\n",
    "# =============================================\n",
    "\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, base_path, patient_list, labels_dict, slice_idx=120, selected_modalities=None):\n",
    "        \"\"\"\n",
    "        Dataset for multi-channel 2D MRI slices\n",
    "\n",
    "        Args:\n",
    "            base_path: Path to folder containing patient folders\n",
    "            patient_list: List of patient folder names to include\n",
    "            labels_dict: Dictionary mapping folder_name -> label\n",
    "            slice_idx: Which slice to extract from 3D volume (default: 120)\n",
    "            selected_modalities: List of modality names to use. If None, uses all available.\n",
    "        \"\"\"\n",
    "        self.base_path = base_path\n",
    "        self.patient_list = patient_list\n",
    "        self.labels_dict = labels_dict\n",
    "        self.slice_idx = slice_idx\n",
    "\n",
    "        # Define modality order (consistent for all patients)\n",
    "        # Excluding non-NIfTI files and segmentation masks\n",
    "        self.all_modalities = [\n",
    "            'ADC', 'FLAIR', 'T1', 'T1c', 'T2', \"brain_segmentation\", \"tumor_segmentation\"\n",
    "        ]\n",
    "\n",
    "        # Use selected modalities or all\n",
    "        self.modalities = selected_modalities if selected_modalities else self.all_modalities\n",
    "\n",
    "        print(f\"Using {len(self.modalities)} modalities: {self.modalities[:3]}... (showing first 3)\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patient_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient_folder = self.patient_list[idx]\n",
    "        patient_id = patient_folder.replace('_nifti', '')\n",
    "        patient_path = Path(self.base_path) / patient_folder  # ✅ Pathlib join\n",
    "\n",
    "        channels = []\n",
    "        for modality in self.modalities:\n",
    "            file_path = patient_path / f\"{patient_id}_{modality}.nii.gz\"  # ✅ Safe path\n",
    "\n",
    "            try:\n",
    "                # Load 3D volume\n",
    "                img_3d = nib.load(str(file_path)).get_fdata().astype(np.float32)  # ✅ Convert to string\n",
    "\n",
    "                # Extract 2D slice\n",
    "                if img_3d.shape[2] > self.slice_idx:\n",
    "                    img_2d = img_3d[:, :, self.slice_idx]\n",
    "                else:\n",
    "                    img_2d = img_3d[:, :, img_3d.shape[2] // 2]\n",
    "\n",
    "                # Normalize to [0, 1]\n",
    "                img_min, img_max = img_2d.min(), img_2d.max()\n",
    "                if img_max > img_min:\n",
    "                    img_2d = (img_2d - img_min) / (img_max - img_min)\n",
    "                else:\n",
    "                    img_2d = np.zeros_like(img_2d)\n",
    "\n",
    "                channels.append(img_2d)\n",
    "\n",
    "            except Exception as e:\n",
    "                # If file missing or error, use zero-filled channel\n",
    "                print(f\"Warning: Could not load {modality} for {patient_folder}: {e}\")\n",
    "                channels.append(np.zeros((240, 240), dtype=np.float32))\n",
    "\n",
    "        # Stack channels: (num_channels, H, W)\n",
    "        img_tensor = np.stack(channels, axis=0)\n",
    "        label = self.labels_dict[patient_folder]\n",
    "\n",
    "         # Get label\n",
    "        label = self.labels_dict[patient_folder]\n",
    "\n",
    "        return torch.tensor(img_tensor, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# =============================================\n",
    "# 3. CNN MODEL\n",
    "# =============================================\n",
    "\n",
    "class CNN2D(nn.Module):\n",
    "    def __init__(self, n_channels=7, n_classes=3):\n",
    "        \"\"\"\n",
    "        2D CNN for multi-channel MRI classification\n",
    "\n",
    "        Args:\n",
    "            n_channels: Number of input channels (MRI modalities)\n",
    "            n_classes: Number of output classes (3 for WHO grades 2,3,4)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # Block 1: n_channels -> 32\n",
    "            nn.Conv2d(n_channels, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 240x240 -> 120x120\n",
    "\n",
    "            # Block 2: 32 -> 64\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 120x120 -> 60x60\n",
    "\n",
    "            # Block 3: 64 -> 128\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 60x60 -> 30x30\n",
    "\n",
    "            # Block 4: 128 -> 256\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 30x30 -> 15x15\n",
    "        )\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(256 * 15 * 15, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# 4. TRAINING FUNCTION\n",
    "# =============================================\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5, device='cuda'):\n",
    "    \"\"\"\n",
    "    Train the CNN model\n",
    "\n",
    "    Returns:\n",
    "        train_losses, val_losses, train_accs, val_accs\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100. * correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = 100. * correct / total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# 5. MAIN EXECUTION\n",
    "# =============================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths\n",
    "    csv_path = \"fall-2025-brain-tumor-diagnosis/Clinical-data/UCSF-PDGM-metadata_v5.csv\"\n",
    "    base_path = r\"G:/Shared drives/Fall2025BrainTumorDiagnosis/\"\n",
    "\n",
    "    # Load labels\n",
    "    labels_dict, all_patients = load_labels(csv_path, base_path)\n",
    "\n",
    "    # Get patients with labels\n",
    "    patients_with_labels = list(labels_dict.keys())\n",
    "\n",
    "    # Train/val split (80/20)\n",
    "    train_patients, val_patients = train_test_split(\n",
    "        patients_with_labels, test_size=0.2, random_state=42,\n",
    "        stratify=[labels_dict[p] for p in patients_with_labels]\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTrain: {len(train_patients)}, Val: {len(val_patients)}\")\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = MRIDataset(base_path, train_patients, labels_dict, slice_idx=120)\n",
    "    val_dataset = MRIDataset(base_path, val_patients, labels_dict, slice_idx=120)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Initialize model\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "    model = CNN2D(n_channels=7, n_classes=3)\n",
    "\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train\n",
    "    print(\"\\nStarting training...\")\n",
    "    train_losses, val_losses, train_accs, val_accs = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer,\n",
    "        num_epochs=20, device=device\n",
    "    )\n",
    "\n",
    "    # Plot results\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    ax1.plot(train_losses, label='Train Loss')\n",
    "    ax1.plot(val_losses, label='Val Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "\n",
    "    ax2.plot(train_accs, label='Train Acc')\n",
    "    ax2.plot(val_accs, label='Val Acc')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    ax2.set_title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t6Dbzls8zGv3",
    "outputId": "5977ae1e-e1fa-4517-9308-9ae88362ce18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced LR: 0.0003\n"
     ]
    }
   ],
   "source": [
    "for g in optimizer.param_groups:\n",
    "    g['lr'] = g['lr'] * 0.3\n",
    "print(\"Reduced LR:\", optimizer.param_groups[0]['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltr82i4BRwQ-"
   },
   "source": [
    "#Save the model to Google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8s-tRGPnRtHf"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9Y1YK_8Rtlu"
   },
   "outputs": [],
   "source": [
    "save_path = \"/content/drive/MyDrive/brain_tumor_cnn/model_final.pth\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(\"Model saved to:\", save_path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "erdos_ds_environment",
   "language": "python",
   "name": "erdos_ds_environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
